{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hew/python/genhance\n",
      "\u001B[0m\u001B[01;34mACE2\u001B[0m/  \u001B[01;34mdebug\u001B[0m/  \u001B[01;34moutput\u001B[0m/  \u001B[01;34mtensorboard\u001B[0m/\r\n",
      "\u001B[01;34mdata\u001B[0m/  \u001B[01;34mfoldx\u001B[0m/  \u001B[01;34mtemp\u001B[0m/    \u001B[01;34mtransformers_custom\u001B[0m/\r\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd '/home/hew/python/genhance/'\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr 10 03:27:51 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:05.0 Off |                    0 |\r\n",
      "| N/A   36C    P0    68W / 400W |      0MiB / 81920MiB |      0%      Default |\r\n",
      "|                               |                      |             Disabled |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA A100-SXM...  Off  | 00000000:00:06.0 Off |                    0 |\r\n",
      "| N/A   34C    P0    67W / 400W |      0MiB / 81920MiB |      0%      Default |\r\n",
      "|                               |                      |             Disabled |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  NVIDIA A100-SXM...  Off  | 00000000:00:07.0 Off |                    0 |\r\n",
      "| N/A   34C    P0    68W / 400W |      0MiB / 81920MiB |     24%      Default |\r\n",
      "|                               |                      |             Disabled |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   3  NVIDIA A100-SXM...  Off  | 00000000:00:08.0 Off |                    0 |\r\n",
      "| N/A   65C    P0   389W / 400W |  47729MiB / 81920MiB |     93%      Default |\r\n",
      "|                               |                      |             Disabled |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    3   N/A  N/A     35187      C   .../envs/genhance/bin/python    47726MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from transformers import T5Tokenizer\n",
    "from transformers_custom import MT5ForConditionalGenerationWithLatentSpace"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "input_data_dir = '/home/hew/storage/storage/genhance/data/'\n",
    "gen_pretrained_dir = '/home/hew/storage/storage/genhance/ckpts/congen2/results/step_42000/'\n",
    "generation_output_dir = '/home/hew/storage/storage/genhance/ckpts/congen2/generations/'\n",
    "prepend_output_name = 'step42000'\n",
    "\n",
    "topk_as_input = 12500\n",
    "num_generations = 250000\n",
    "num_gen_samples_per_input = 20\n",
    "gen_batch_size = 200\n",
    "unique_gen = True\n",
    "temperature_init = 1.0\n",
    "temperature_multiple = 1.2\n",
    "gen_token_len = 83 + 2 + 1  # 83 ACE2 domain length + <cls> + </s> + <pad> token (decoder input_ids), other special tokens has been pruned\n",
    "gen_save_interval = 100\n",
    "z_tar_edit_before_dec = -1.0\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "Namespace(beta=1.0, beta_ratio_increase=0.25, beta_ratio_zero=0.25, beta_start_step=10000, cache_dir='/home/hew/storage/storage/genhance/pretrained/', contrastive_cyc_start_step=10000, contrastive_perturb_cyc_start_step=-1, data_dir='/home/hew/storage/storage/genhance/data/', dim_target_kl=0.5, do_mi=False, eval_split_name='valid', eval_steps=200, lambda_contrastive=1.0, lambda_contrastive_cyc=1.0, lambda_contrastive_perturb_cyc=0.0, lambda_logvar_KL=0.0, lambda_logvar_L1=0.0, lambda_mi_head_loss=1.0, latent_pooler='cls', latent_size=1024, latent_space_type='wae', logging_dir='/home/hew/python/genhance/tensorboard/congen2', logging_steps=20, lr=0.0001, mask_non_target_z_vector=False, mmd_method='rf', num_decode_layers=6, num_layers=6, num_train_epochs=30, num_warmup_steps=0, output_dir='/home/hew/storage/storage/genhance/ckpts/congen2/results/', pc_perturb=-0.25, pc_perturb_type='std', per_device_eval_batch_size=256, per_device_train_batch_size=80, pool_enc_hidden_states_for_dec=True, pretrained_dir='/home/hew/storage/storage/genhance/pretrained/', property='ddG', rf_dim_mmd=None, save_steps=1000, save_total_limit=30, seed=42, separate_latent_dec=False, separate_latent_enc=False, separate_targetattr_head=False, sigma_mmd=None, src_json='/home/hew/python/genhance/temp/config.json', train_ratio=0.9, train_split_name='train', use_beta_schedule=False, wae_z_enc_type='deterministic', warmup_steps=500, weight_decay=0.01, z_tar_vector_dim=1)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_args = torch.load(gen_pretrained_dir + '/training_args.bin')\n",
    "latent_space_args = {\n",
    "    'latent_pooler'                 : ckpt_args.latent_pooler,\n",
    "    'pool_enc_hidden_states_for_dec': ckpt_args.pool_enc_hidden_states_for_dec,\n",
    "    'mask_non_target_z_vector'      : ckpt_args.mask_non_target_z_vector,\n",
    "    'separate_targetattr_head'      : ckpt_args.separate_targetattr_head,\n",
    "    'z_tar_vector_dim'              : ckpt_args.z_tar_vector_dim,\n",
    "    'do_mi'                         : ckpt_args.do_mi,\n",
    "    'latent_space_type'             : ckpt_args.latent_space_type,\n",
    "    'latent_size'                   : ckpt_args.latent_size,\n",
    "    'separate_latent_enc'           : ckpt_args.separate_latent_enc,\n",
    "    'separate_latent_dec'           : ckpt_args.separate_latent_dec,\n",
    "    'wae_z_enc_type'                : ckpt_args.wae_z_enc_type,\n",
    "    }\n",
    "ckpt_args"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"Rostlab/prot_t5_xl_uniref50\", cache_dir=ckpt_args.cache_dir)\n",
    "tokenizer.add_special_tokens({\"cls_token\": \"<cls>\"})\n",
    "assert tokenizer.cls_token == \"<cls>\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "{'<pad>': 0,\n '</s>': 1,\n '<unk>': 2,\n '▁A': 3,\n '▁L': 4,\n '▁G': 5,\n '▁V': 6,\n '▁S': 7,\n '▁R': 8,\n '▁E': 9,\n '▁D': 10,\n '▁T': 11,\n '▁I': 12,\n '▁P': 13,\n '▁K': 14,\n '▁F': 15,\n '▁Q': 16,\n '▁N': 17,\n '▁Y': 18,\n '▁M': 19,\n '▁H': 20,\n '▁W': 21,\n '▁C': 22,\n '▁X': 23,\n '▁B': 24,\n '▁O': 25,\n '▁U': 26,\n '▁Z': 27,\n '<extra_id_99>': 28,\n '<extra_id_98>': 29,\n '<extra_id_97>': 30,\n '<extra_id_96>': 31,\n '<extra_id_95>': 32,\n '<extra_id_94>': 33,\n '<extra_id_93>': 34,\n '<extra_id_92>': 35,\n '<extra_id_91>': 36,\n '<extra_id_90>': 37,\n '<extra_id_89>': 38,\n '<extra_id_88>': 39,\n '<extra_id_87>': 40,\n '<extra_id_86>': 41,\n '<extra_id_85>': 42,\n '<extra_id_84>': 43,\n '<extra_id_83>': 44,\n '<extra_id_82>': 45,\n '<extra_id_81>': 46,\n '<extra_id_80>': 47,\n '<extra_id_79>': 48,\n '<extra_id_78>': 49,\n '<extra_id_77>': 50,\n '<extra_id_76>': 51,\n '<extra_id_75>': 52,\n '<extra_id_74>': 53,\n '<extra_id_73>': 54,\n '<extra_id_72>': 55,\n '<extra_id_71>': 56,\n '<extra_id_70>': 57,\n '<extra_id_69>': 58,\n '<extra_id_68>': 59,\n '<extra_id_67>': 60,\n '<extra_id_66>': 61,\n '<extra_id_65>': 62,\n '<extra_id_64>': 63,\n '<extra_id_63>': 64,\n '<extra_id_62>': 65,\n '<extra_id_61>': 66,\n '<extra_id_60>': 67,\n '<extra_id_59>': 68,\n '<extra_id_58>': 69,\n '<extra_id_57>': 70,\n '<extra_id_56>': 71,\n '<extra_id_55>': 72,\n '<extra_id_54>': 73,\n '<extra_id_53>': 74,\n '<extra_id_52>': 75,\n '<extra_id_51>': 76,\n '<extra_id_50>': 77,\n '<extra_id_49>': 78,\n '<extra_id_48>': 79,\n '<extra_id_47>': 80,\n '<extra_id_46>': 81,\n '<extra_id_45>': 82,\n '<extra_id_44>': 83,\n '<extra_id_43>': 84,\n '<extra_id_42>': 85,\n '<extra_id_41>': 86,\n '<extra_id_40>': 87,\n '<extra_id_39>': 88,\n '<extra_id_38>': 89,\n '<extra_id_37>': 90,\n '<extra_id_36>': 91,\n '<extra_id_35>': 92,\n '<extra_id_34>': 93,\n '<extra_id_33>': 94,\n '<extra_id_32>': 95,\n '<extra_id_31>': 96,\n '<extra_id_30>': 97,\n '<extra_id_29>': 98,\n '<extra_id_28>': 99,\n '<extra_id_27>': 100,\n '<extra_id_26>': 101,\n '<extra_id_25>': 102,\n '<extra_id_24>': 103,\n '<extra_id_23>': 104,\n '<extra_id_22>': 105,\n '<extra_id_21>': 106,\n '<extra_id_20>': 107,\n '<extra_id_19>': 108,\n '<extra_id_18>': 109,\n '<extra_id_17>': 110,\n '<extra_id_16>': 111,\n '<extra_id_15>': 112,\n '<extra_id_14>': 113,\n '<extra_id_13>': 114,\n '<extra_id_12>': 115,\n '<extra_id_11>': 116,\n '<extra_id_10>': 117,\n '<extra_id_9>': 118,\n '<extra_id_8>': 119,\n '<extra_id_7>': 120,\n '<extra_id_6>': 121,\n '<extra_id_5>': 122,\n '<extra_id_4>': 123,\n '<extra_id_3>': 124,\n '<extra_id_2>': 125,\n '<extra_id_1>': 126,\n '<extra_id_0>': 127,\n '<cls>': 128}"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_vocab()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "input_data_path = Path(input_data_dir)\n",
    "input_data_file = f'train_tophalf_ddG_solubility.pkl'\n",
    "input_data_file = input_data_path/input_data_file\n",
    "input_data_df = pd.read_pickle(input_data_file)\n",
    "train_seq_list = input_data_df['MT_seq'].tolist()\n",
    "ddG_sorted_input_df = input_data_df.sort_values(by='ddG', ascending=True)\n",
    "gen_input_df = ddG_sorted_input_df.iloc[:topk_as_input]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "(125000, 125000, 12500)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_seq_list), len(ddG_sorted_input_df), len(gen_input_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "if num_generations is None:\n",
    "    num_generations = topk_as_input*num_gen_samples_per_input\n",
    "num_unique_seqs_per_batch = gen_batch_size//num_gen_samples_per_input\n",
    "num_batch = len(gen_input_df)//num_unique_seqs_per_batch\n",
    "if len(gen_input_df)%num_unique_seqs_per_batch != 0:\n",
    "    num_batch += 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "generation conifg:\n",
      "num_generations:  250000\n",
      "topk_as_input:  12500\n",
      "num_gen_samples_per_input:  20\n",
      "num_unique_seqs_per_batch:  10\n",
      "num_batch:  1250\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*100)\n",
    "print('generation conifg:')\n",
    "print('num_generations: ', num_generations)\n",
    "print('topk_as_input: ', topk_as_input)\n",
    "print('num_gen_samples_per_input: ', num_gen_samples_per_input)\n",
    "print('num_unique_seqs_per_batch: ', num_unique_seqs_per_batch)\n",
    "print('num_batch: ', num_batch)\n",
    "print(\"=\"*100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## from_pretrained"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== T5 Model T5ForConditionalGenerationWithLatentSpace Initialization start ====================\n",
      "========== Initialize T5ForConditionalGenerationWithLatentSpace ==========\n",
      "latent_space_type:  wae\n",
      "wae_z_enc_type:  deterministic\n",
      "separate_latent_enc:  False\n",
      "separate_latent_dec:  False\n",
      "mmd_method:  rf\n",
      "sigma_mmd:  None\n",
      "rf_dim_mmd:  None\n",
      "dim_target_kl:  0.5\n",
      "latent_size:  1024\n",
      "latent_pooler:  cls\n",
      "pool_enc_hidden_states_for_dec:  True\n",
      "mask_non_target_z_vector:  False\n",
      "separate_targetattr_head:  False\n",
      "do_mi:  False\n",
      "========== Initialize T5ForConditionalGenerationWithLatentSpace ==========\n",
      "==================== T5 Model T5ForConditionalGenerationWithLatentSpace Initialization end ====================\n",
      "CPU times: user 55.3 s, sys: 13.4 s, total: 1min 8s\n",
      "Wall time: 55.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": "Embedding(129, 1024)"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "gen_model = MT5ForConditionalGenerationWithLatentSpace.from_pretrained(gen_pretrained_dir,\n",
    "                                                                       cache_dir=ckpt_args.cache_dir,\n",
    "                                                                       num_layers=ckpt_args.num_layers,\n",
    "                                                                       num_decoder_layers=ckpt_args.num_decoder_layers if\n",
    "                                                                       'num_decoder_layers' in ckpt_args else ckpt_args.num_decode_layers,\n",
    "                                                                       **latent_space_args)\n",
    "gen_model.parallelize()\n",
    "gen_model.resize_token_embeddings(len(tokenizer))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda', index=0)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_model.device"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "output_seq_list = []\n",
    "input_seq_list = []\n",
    "output_tensor_list = []\n",
    "repeat_list = []\n",
    "in_train_data_list = []\n",
    "unique_n_notrain_list = []\n",
    "start_time = time.time()\n",
    "prev_save_path = None\n",
    "repeat_seq_count = 0\n",
    "in_train_count = 0\n",
    "temperature = temperature_init\n",
    "generation_rounds_done = 0\n",
    "num_cls_seq = 0\n",
    "num_fail_seq = 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "83"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt_seq = 'STIEEQAKTFLDKFNHEAEDLFYQSSLASWNYNTNITEENVQNMNNAGDKWSAFLKEQSTLAQMYPLQEIQNLTVKLQLQALQ'\n",
    "len(wt_seq)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "([[0],\n  [2],\n  [23],\n  [24],\n  [25],\n  [26],\n  [27],\n  [28],\n  [29],\n  [30],\n  [31],\n  [32],\n  [33],\n  [34],\n  [35],\n  [36],\n  [37],\n  [38],\n  [39],\n  [40],\n  [41],\n  [42],\n  [43],\n  [44],\n  [45],\n  [46],\n  [47],\n  [48],\n  [49],\n  [50],\n  [51],\n  [52],\n  [53],\n  [54],\n  [55],\n  [56],\n  [57],\n  [58],\n  [59],\n  [60],\n  [61],\n  [62],\n  [63],\n  [64],\n  [65],\n  [66],\n  [67],\n  [68],\n  [69],\n  [70],\n  [71],\n  [72],\n  [73],\n  [74],\n  [75],\n  [76],\n  [77],\n  [78],\n  [79],\n  [80],\n  [81],\n  [82],\n  [83],\n  [84],\n  [85],\n  [86],\n  [87],\n  [88],\n  [89],\n  [90],\n  [91],\n  [92],\n  [93],\n  [94],\n  [95],\n  [96],\n  [97],\n  [98],\n  [99],\n  [100],\n  [101],\n  [102],\n  [103],\n  [104],\n  [105],\n  [106],\n  [107],\n  [108],\n  [109],\n  [110],\n  [111],\n  [112],\n  [113],\n  [114],\n  [115],\n  [116],\n  [117],\n  [118],\n  [119],\n  [120],\n  [121],\n  [122],\n  [123],\n  [124],\n  [125],\n  [126],\n  [127]],\n 107)"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_words_ids = [0, 2] + list(range(23, 127 + 1))\n",
    "bad_words_ids = [[x] for x in bad_words_ids]\n",
    "bad_words_ids, len(bad_words_ids)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_input_ids.shape:  torch.Size([200, 85])\n",
      "batch_input_ids[0]:  85 tensor([128,   7,  11,  12,   9,   9,  16,   3,  14,  11,  15,   4,  10,  14,\n",
      "         15,  17,  20,   9,  14,   9,  10,   4,  15,  18,  16,   7,   7,   4,\n",
      "          3,  12,  21,  17,  18,  17,  11,  17,  12,  11,   9,   9,  17,   6,\n",
      "         16,  17,  19,  17,  15,   3,  16,  10,  14,  21,   7,   3,  15,   4,\n",
      "         14,   9,  16,   7,  11,   4,   3,  16,  19,  18,  13,   4,  16,   9,\n",
      "         12,  16,  17,   4,  11,   6,  14,   4,  15,   4,  16,   3,   4,  19,\n",
      "          1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1250 [00:10<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen_output.shape:  torch.Size([200, 86])\n",
      "gen_output:  tensor([  0, 128,   7,  11,  12,   9,   9,  16,   3,  14,  11,  15,   4,  10,\n",
      "         14,  15,  17,  20,   9,  14,   9,  10,   4,  15,  18,  16,   7,   7,\n",
      "          4,   3,  12,  21,  17,  18,  17,  11,  17,  12,  11,   9,   9,  17,\n",
      "          6,  16,  17,  19,  17,  15,   3,  16,  10,  14,  21,   7,   3,  15,\n",
      "          4,  14,   9,  16,   7,  11,   4,   3,  16,  19,  18,  13,   4,  16,\n",
      "          9,  12,  16,  17,   4,  11,   6,  14,   4,  15,   4,  16,   3,   4,\n",
      "         19,  15], device='cuda:0')\n",
      "[0] str_token_seq:  STIEEQAKTFLDKFNHEKEDLFYQSSLAIWNYNTNITEENVQNMNFAQDKWSAFLKEQSTLAQMYPLQEIQNLTVKLFLQALM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[69], line 55\u001B[0m\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m num_cls_seq\u001B[38;5;241m%\u001B[39m\u001B[38;5;241m100\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m     51\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum failed gen: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(num_fail_seq),\n\u001B[1;32m     52\u001B[0m               \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m, num valid gen: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(np\u001B[38;5;241m.\u001B[39msum(unique_n_notrain_list)),\n\u001B[1;32m     53\u001B[0m               \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m, gen/total: \u001B[39m\u001B[38;5;132;01m{:.2f}\u001B[39;00m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(np\u001B[38;5;241m.\u001B[39msum(unique_n_notrain_list)\u001B[38;5;241m/\u001B[39mnum_generations\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m100\u001B[39m))\n\u001B[0;32m---> 55\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m()  \u001B[38;5;66;03m# debug\u001B[39;00m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m str_token_seq \u001B[38;5;129;01min\u001B[39;00m output_seq_list:\n\u001B[1;32m     58\u001B[0m     repeat_seq_count \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "gen_model.eval()\n",
    "while unique_gen and np.sum(unique_n_notrain_list) < num_generations:\n",
    "    if generation_rounds_done > 0:\n",
    "        temperature = temperature*temperature_multiple\n",
    "        print(\"New generation round, temperature: \", temperature,\n",
    "              \"num_unique_n_notrain_list: \", np.sum(unique_n_notrain_list))\n",
    "\n",
    "    for batch_ind in tqdm(range(num_batch)):\n",
    "        batch_seqs = gen_input_df[batch_ind*num_unique_seqs_per_batch: (batch_ind + 1)*num_unique_seqs_per_batch]['MT_seq']\n",
    "\n",
    "        batch_input_ids = []\n",
    "        batch_input_seqs = []\n",
    "        for seq in batch_seqs:\n",
    "            batch_input_seqs = batch_input_seqs + [seq]*num_gen_samples_per_input\n",
    "            seq = '<cls> ' + \" \".join(list(re.sub(r\"[UZOB]\", \"X\", seq)))\n",
    "            input_ids = tokenizer.encode(seq, return_tensors='pt').to(gen_model.device)\n",
    "            repeated_input_ids = input_ids.repeat((num_gen_samples_per_input, 1))\n",
    "            batch_input_ids.append(repeated_input_ids)\n",
    "\n",
    "        batch_input_ids = torch.cat(batch_input_ids, dim=0)\n",
    "        print(\"batch_input_ids.shape: \", batch_input_ids.shape)\n",
    "        print(\"batch_input_ids[0]: \", len(batch_input_ids[0]), batch_input_ids[0])\n",
    "\n",
    "        gen_output = gen_model.generate(batch_input_ids,\n",
    "                                        max_length=83 + 2 + 1,\n",
    "                                        min_length=83 + 2 + 1,\n",
    "                                        do_sample=True,\n",
    "                                        temperature=temperature,\n",
    "                                        bad_words_ids=bad_words_ids,\n",
    "                                        z_tar_edit_before_dec=z_tar_edit_before_dec)\n",
    "        print(\"gen_output.shape: \", gen_output.shape)  # torch.Size([200, 86])\n",
    "        print('gen_output: ', gen_output[0])\n",
    "        for seq_ind, gen_seq in enumerate(gen_output.cpu().numpy()):\n",
    "            unique_n_notrain = True\n",
    "            repeat = False\n",
    "            in_train_data = False\n",
    "\n",
    "            tokens = tokenizer.convert_ids_to_tokens(gen_seq.tolist())\n",
    "            # print(\"len(tokens): \", len(tokens)) # 86\n",
    "            if tokens == None or len(tokens) != gen_token_len:\n",
    "                continue\n",
    "\n",
    "            # print(\"tokens[:2]: \", tokens[:2])  # ['<pad>', '<cls>']\n",
    "            # print(\"gen_seq[:2]: \", gen_seq[:2])  # [0 128]\n",
    "            str_token_seq = \"\".join(tokens[2:-1]).replace('▁', '')\n",
    "            print(f\"[{seq_ind}] str_token_seq: \", str_token_seq)\n",
    "\n",
    "            if num_fail_seq%1000 == 0 or np.sum(unique_n_notrain_list)%1000 == 0:\n",
    "                num_cls_seq += 1\n",
    "                if num_cls_seq%100 == 0:\n",
    "                    print(\"num failed gen: {},\".format(num_fail_seq),\n",
    "                          \", num valid gen: {},\".format(np.sum(unique_n_notrain_list)),\n",
    "                          \", gen/total: {:.2f}%\".format(np.sum(unique_n_notrain_list)/num_generations*100))\n",
    "\n",
    "            raise RuntimeError()  # debug\n",
    "\n",
    "            if str_token_seq in output_seq_list:\n",
    "                repeat_seq_count += 1\n",
    "                repeat = True\n",
    "                unique_n_notrain = False\n",
    "\n",
    "            if str_token_seq in train_seq_list:\n",
    "                in_train_count += 1\n",
    "                in_train_data = True\n",
    "                unique_n_notrain = False\n",
    "\n",
    "            if unique_gen and not unique_n_notrain:\n",
    "                continue\n",
    "\n",
    "            unique_n_notrain_list.append(unique_n_notrain)\n",
    "            repeat_list.append(repeat)\n",
    "            in_train_data_list.append(in_train_data)\n",
    "\n",
    "            input_seq_str = batch_input_seqs[seq_ind]\n",
    "            input_seq_list.append(input_seq_str)\n",
    "            output_seq_list.append(str_token_seq)\n",
    "\n",
    "            seq_tensor = gen_output[seq_ind].detach().cpu()\n",
    "            output_tensor_list.append(seq_tensor)\n",
    "\n",
    "        if batch_ind%gen_save_interval == 0 and batch_ind != 0:\n",
    "            save_path = os.path.join(generation_output_dir,\n",
    "                                     \"{}-gens-{}-{}.pkl\".format(prepend_output_name,\n",
    "                                                                len(output_seq_list),\n",
    "                                                                num_generations))\n",
    "            saved_dict = {\n",
    "                'output_seq_list': output_seq_list, \"input_seq_list\": input_seq_list, \"output_tensor_list\": output_tensor_list,\n",
    "                'repeat_list'    : repeat_list, 'in_train_data_list': in_train_data_list, 'temperature': temperature\n",
    "                }\n",
    "            with open(save_path, 'wb') as f:\n",
    "                pickle.dump(saved_dict, f)\n",
    "            cur_time = time.time()\n",
    "\n",
    "            print('='*50, 'interval save', '='*50)\n",
    "            print(\"generated #\", len(output_seq_list))\n",
    "            print(\"Time taken so far: {} hours\".format((cur_time - start_time)/3600))\n",
    "            print('='*50, 'interval save', '='*50)\n",
    "\n",
    "            if prev_save_path is not None:\n",
    "                os.remove(prev_save_path)\n",
    "            prev_save_path = save_path\n",
    "\n",
    "        if unique_gen and np.sum(unique_n_notrain_list) > num_generations:\n",
    "            break\n",
    "    generation_rounds_done += 1\n",
    "\n",
    "'''Save Final Data'''\n",
    "save_path = os.path.join(generation_output_dir, \"{}-gens-{}.pkl\".format(prepend_output_name,\n",
    "                                                                        num_generations))\n",
    "saved_dict = {\n",
    "    'output_seq_list': output_seq_list, \"input_seq_list\": input_seq_list, \"output_tensor_list\": output_tensor_list,\n",
    "    'repeat_list'    : repeat_list, 'in_train_data_list': in_train_data_list, 'temperature': temperature\n",
    "    }\n",
    "with open(save_path, 'wb') as f:\n",
    "    pickle.dump(saved_dict, f)\n",
    "\n",
    "if prev_save_path is not None:\n",
    "    os.remove(prev_save_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([200, 85]), torch.Size([200, 86]))"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_input_ids.shape, gen_output.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([128,   7,  11,  12,   9,   9,  16,   3,  14,  11,  15,   4,  10,  14,\n         15,  17,  20,   9,  14,   9,  10,   4,  15,  18,  16,   7,   7,   4,\n          3,  12,  21,  17,  18,  17,  11,  17,  12,  11,   9,   9,  17,   6,\n         16,  17,  19,  17,  15,   3,  16,  10,  14,  21,   7,   3,  15,   4,\n         14,   9,  16,   7,  11,   4,   3,  16,  19,  18,  13,   4,  16,   9,\n         12,  16,  17,   4,  11,   6,  14,   4,  15,   4,  16,   3,   4,  19,\n          1], device='cuda:0')"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_input_ids[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([  0, 128,   7,  11,  12,   9,   9,  16,   3,  14,  11,  15,   4,  10,\n         14,  15,  17,  20,   9,  14,   9,  10,   4,  15,  18,  16,   7,   7,\n          4,   3,  12,  21,  17,  18,  17,  11,  17,  12,  11,   9,   9,  17,\n          6,  16,  17,  19,  17,  15,   3,  16,  10,  14,  21,   7,   3,  15,\n          4,  14,   9,  16,   7,  11,   4,   3,  16,  19,  18,  13,   4,  16,\n          9,  12,  16,  17,   4,  11,   6,  14,   4,  15,   4,  16,   3,   4,\n         19,  15], device='cuda:0')"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_output[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 7, 11, 12,  9,  9, 16,  3, 14, 11, 15,  4, 10, 14, 15, 17, 20,  9, 14,\n         9, 10,  4, 15, 18, 16,  7,  7,  4,  3, 12, 21, 17, 18, 17, 11, 17, 12,\n        11,  9,  9, 17,  6, 16, 17, 19, 17, 15,  3, 16, 10, 14, 21,  7,  3, 15,\n         4, 14,  9, 16,  7, 11,  4,  3, 16, 19, 18, 13,  4, 16,  9, 12, 16, 17,\n         4, 11,  6, 14,  4, 15,  4, 16,  3,  4, 19], device='cuda:0')"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_output[0][2:-1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "('STIEEQAKTFLDKFNHEKEDLFYQSSLAIWNYNTNITEENVQNMNFAQDKWSAFLKEQSTLAQMYPLQEIQNLTVKLFLQALM',\n 83)"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_seq = str_token_seq\n",
    "gen_seq, len(gen_seq)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "('STIEEQAKTFLDKFNHEAEDLFYQSSLASWNYNTNITEENVQNMNNAGDKWSAFLKEQSTLAQMYPLQEIQNLTVKLQLQALQ',\n 83)"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt_seq, len(wt_seq)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "6"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = 0\n",
    "for i in range(len(gen_seq)):\n",
    "    if gen_seq[i] != wt_seq[i]:\n",
    "        dist += 1\n",
    "dist"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
